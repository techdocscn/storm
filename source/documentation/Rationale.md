---
layout: documentation
---
数据处理在过去的十几年里发生了革命性的变化。MapReduce, Hadoop, 以及其他相关的技术使得处理以前无法想象的规模的数据成为可能。很不幸，这些数据处理的技术从设计上就不是为了实时处理。无论怎样，Hadoop 都没办法被 hack 成为实时系统；实时数据处理从根本上与批处理有着不同的需求。

然而，对于公司来说，能够实时的处理超大规模数据已经迫在眉睫。“实时 Hadoop”的缺乏已经成了数据处理生物链中最大的空缺。

Storm 应运而生。

在 Storm 之前, 你一般需要手动的建立一个 queue 和 worker 的网络来做实时处理。每个 worker 要从 queue 中摘除一个消息， 更新数据库， 再发新的消息到其他的queue来对数据做更进一步的处理。很不幸，这个方法存在以下局限性：

1. **乏味**: 你需要用开发时间的绝大部分配置向哪儿发送消息，部署 workers， 部署中间的queue。你所关心的实时数据处理逻辑只占项目代码相对很小的一部分。
2. **脆弱**: 容错率极低。你需要保证每个 worker 和 queue 的正常运行。
3. **极难扩展**: 当某一个 worker 或者 queue 的吞吐率变得很高的时候，你需要通过分割来分散数据。你需要重新配置其他的 workers 让他们向新的地方发送消息。这就向系统中引入了新的可能失效的部分。

虽然 queue 和 worker 的范例在消息量大的情况下表现不甚理想，消息处理（message processing）仍然是实时计算的根本。问题是，怎样来协调这其中的关系，使得系统不会丢失数据，可以扩展到超高数据量，并且使用和操作起来超级简单？

Storm 可以达到这些目标！ 

## 为神马 Storm 如此重要

Storm 为实时计算提供了一系列的原语。类似于 MapReduce 极大地简化了编写并行批处理，Storm 的原语极大地简化了编写并行实时计算。

Storm 的关键特性有：

1. **超级宽泛的应用场景**: Storm 可以处理消息和更新数据库（流处理）；连续查询（continuous query）数据流，并把结果流传给下游用户（连续计算）；把某些计算量大的查询并行化，比如即时搜索（分布式 RPC ）等等。Storm 很小的原语集能满足数量惊人的应用场景。
2. **可扩展性**: Storm 可以扩展到处理每秒超大量消息。如果要扩展 topology ，你只需要向 topology 里添加更多的机器，并且调高设定中得并发数。比如，一个 Storm 最初的项目仅用了10个结点，就处理了每秒1,000,000条消息。这些消息包括每秒钟几百个的数据库调用。Storm 在 Zookeeper 中起到协调集群的作用，使得集群扩展到更大的规模。
3. **保证无数据丢失**: 实时系统必须保证数据的成功处理。可能丢失数据的系统的应用场景非常受限制。Storm 保证每条消息都得到处理，这与其他的系统，比如S4，形成鲜明对比。 
4. **超级健壮**: Storm 集群很少出错，不像 Hadoop 那样的因为难于管理而臭名远扬的系统。让管理 Storm 集群的用户体验尽可能无痛是 Storm 明确的目标。
5. **容错**: 如果在计算过程中发生了错误，Storm 会按需要重新分派任务。Storm 会保证计算可以一直运行，直到你终止运算为止。
6. **与编程语言无关**: 健壮的可扩展的实时处理不应该被局限于某一个平台。Storm topology 和处理组件可以用任意语言定义，这使得 Storm 可以被几乎所有人使用。
